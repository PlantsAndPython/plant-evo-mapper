{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Orthogroup-lens correlation and GO enrichment analysis\n",
    "\n",
    "In this notebook, we perform a GO enrichment analysis on orthogroups that are highly correlated (positively and negatively) with the *stress* and *tissue* lenses we used to construct mapper graphs. the mapper algorithm to the gene expression data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages\n",
    "First thing, import all the necessary packages and methods. Most of these are commonly used python packages, that can be easily installed. The only uncommon package is `goatools` (for: *Gene Ontology Analysis tools*), which can be pip installed. For more information and documentation, check out [this link](https://pypi.org/project/goatools/). We will use the *multipletests* method from the *statsmodels* package to correct for multiple testing when performing statistical tests.\n",
    "\n",
    "We also need to import custom functions defined in  `helper_functions.py`. As the name suggests, one contains several utility functions required to perform tasks such as loading and scaling input data. The other contains the function to compute the *lens* (more on that further down in the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "from helper_functions import loaddata\n",
    "\n",
    "from goatools.utils import read_geneset\n",
    "from goatools.obo_parser import GODag\n",
    "from goatools.anno.idtogos_reader import IdToGosReader\n",
    "from goatools.go_enrichment import GOEnrichmentStudy\n",
    "from goatools.base import download_go_basic_obo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set paths, specify file names\n",
    "Next thing we want to do is set the paths to the directories containing `code`, `data`, and `results`. We also specify input files. The data to be analyzed is stored in two csv files. `clean_metadata.csv` contains the metadata, `clean_RNAseq_OutlierRemoved.csv` contains the gene expression data. \n",
    "\n",
    "The metadata file contains one sample per row, identified by its *SRA*. There are 3172 samples, and for each sample we have 7 descriptive attributes. We are particularly interested in three of them: namely, its plant *family*, *tissue* type and *stress* type. There are 16 different plant families, 8 tissue types and 10 stress types (including *healthy*) represented in the data. The RNAseq file, as the name suggests contains the gene expression for each sample, across a 6335 orthogroups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "projdir = \"../..\"\n",
    "datadir = projdir + \"/data\"\n",
    "resdir = projdir + \"/results/goea\"\n",
    "\n",
    "factorfile = datadir + \"/clean_metadata.csv\"\n",
    "rnafile = datadir + \"/raw_RNAseq_OutlierRemoved.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set factor and level for used for the lens\n",
    "\n",
    "Here, we set the factor, and the corresponding factor level that was used to construct the lens function. In the manuscript we presented the results using the following three combinations:\n",
    "- filterfactor: *stress*, filterlevel: *healthy*\n",
    "- filterfactor: *tissue*, filterlevel: *root*\n",
    "- filterfactor: *tissue*, filterlevel: *leaf*\n",
    "\n",
    "These variables are also used to construct the names of files and directories in which the results will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cover parameter ranges for specified lenses\n",
    "factors = [\"stress\", \"tissue\", \"family\"]\n",
    "filterfactor, filterlevel = (\"tissue\", \"leaf\")\n",
    "if filterfactor == \"stress\":\n",
    "    cubes, overlap = (110, 75)\n",
    "elif filterfactor == \"tissue\":\n",
    "    if filterlevel == \"root\":\n",
    "        cubes, overlap = (110, 90)\n",
    "    elif filterlevel == \"leaf\":\n",
    "        cubes, overlap = (140, 90)\n",
    "    else:\n",
    "        print(\"filterlevel must be root or leaf\")\n",
    "else:\n",
    "    print(\"filterfactor must be stress or tissue\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and the mapper graph\n",
    "\n",
    "The input data (metadata and gene expression) is stored in two separate files, but samples can be matched using the *SRA*. The function `loaddata` does exactly that. It loads both files into pandas dataframes and merges them using the *SRA* as the key. We perform an inner join, to keep only those *SRAs* for which we have metadata as well as gene expression. We also load the saved mapper graph which contains the lens function values used to construct it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "df, orthos = loaddata(factorfile, rnafile, factors)\n",
    "\n",
    "# load saved mapper graph\n",
    "mapf = f\"{filterfactor}_{filterlevel}_mapper_cubes_{cubes}_overlap_{overlap}\"\n",
    "mapf = datadir + \"/saved_mapper_graphs/\" + mapf + \".pkl\"\n",
    "with open(mapf, \"rb\") as fp:\n",
    "    graph = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Orthogroup-lens correlation\n",
    "\n",
    "Now, for each of the 6335 orthogroups, we will compute the Pearson correlation between the orthogroup expression and the lens function values across all samples. Once we have all the correlation coefficients and the corresponding p-values, we will adjust them for multiple testing and put all that data into a pandas dataframe. Uncomment the last two lines of the following cell if you wish to save the dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lens = np.asarray(graph[\"lens\"]).squeeze()\n",
    "corrs = []\n",
    "pvals = []\n",
    "\n",
    "# Compute orthogroup-lens correlation with p-value for each orthogroup\n",
    "for og in orthos:\n",
    "    r, pv = stats.pearsonr(lens, np.asarray(df[og]).squeeze())\n",
    "    corrs.append(r)\n",
    "    pvals.append(pv)\n",
    "\n",
    "# Compute p-values adjusted for multiple testing\n",
    "reject, p_adjust, _, _ = multipletests(pvals, alpha=0.001, method='fdr_bh')\n",
    "\n",
    "# Create a dataframe\n",
    "corrdf = pd.DataFrame({\"Orthogroup\": orthos, \"correlation\": corrs,\n",
    "                       \"pvalues\": pvals, \"adjusted_pvalues\": p_adjust})\n",
    "\n",
    "# # Uncomment to save the dataframe\n",
    "# fname = f\"/goea/{filterfactor}_{filterlevel}_lens_orthogroup_correlations.csv\"\n",
    "# corrdf.to_csv(resdir + fname, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Left and Right tails of the correlation value distribution\n",
    "\n",
    "We have 6335 correlation coefficients. For GO enrichment analysis, we select the 2.5% of the most positive and 2.5% of the most negative coefficient values. This is same as computing 5% of the values that fall in the left and right tails of the distribution of all 6335 coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Filter correlation dataframe to get extreme values (left and right tails)\n",
    "left = 0.025\n",
    "right = 0.975\n",
    "tails = corrdf[\"correlation\"].quantile(q=[left, right])\n",
    "corrdf_left = corrdf.loc[corrdf[\"correlation\"] < tails[left]]\n",
    "corrdf_right = corrdf.loc[corrdf[\"correlation\"] > tails[right]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load orthogroup-GO terms association file\n",
    "\n",
    "This file contains the association between orthogroups, the corresponding TAIR loci and the GO terms associated with those TAIR loci."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file that maps orthogroups to GO terms using TAIR loci\n",
    "fname = datadir + \"/goea/Orthogroup_GO_terms.tsv\"\n",
    "godf = pd.read_csv(fname, sep=\"\\t\")\n",
    "column_names = [\"Orthogroup\", \"TAIRLocus\", \"GO term\", \"GO ID\", \"GO Slim(s)\"]\n",
    "godf.drop_duplicates(subset=column_names, keep=\"first\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare input files for GO enrichment analysis\n",
    "\n",
    "To perform GO enrichment analysis using `goatools`, we need to create input files in the specified formats. First, we need a text file listing all the TAIR loci in the *population* - that is, a text file listing all unique TAIR loci associated with the orthogroups in our data. Second, we need a text file containing the associations between TAIR loci and the GO IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all unique TAIR loci associated with orthogroups and write to a file\n",
    "tair_file = datadir + \"/goea/all_tairs.txt\"\n",
    "with open(tair_file, \"w\") as fp:\n",
    "    fp.write(\"\\n\".join(godf[\"TAIRLocus\"].unique()))\n",
    "\n",
    "# Create TAIR Locus - GO ID associations and write to file\n",
    "assoc_file = datadir + \"/goea/go_association.txt\"\n",
    "tair_grouped = godf.groupby(\"TAIRLocus\")[\"GO ID\"].aggregate(set)\n",
    "with open(assoc_file, \"w\") as fp:\n",
    "    for t in tair_grouped.index:\n",
    "        fp.write(t + \"\\t\" + \";\".join(list(tair_grouped[t])) + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will perform separate GO enrichment analyses for the set of orthogroups most negatively correlated with the lense (prefix: *left_* for left tail), and the set of orthogroups most positively correlated with the lense (prefix: *right_*, for right tail). For GO enrichment analysis, we need to identify the lists of unique TAIR loci associated with those sets of orthogroups and write them to text files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List TAIR loci associated with orthogroups in the left tail and write to file\n",
    "left_file = f\"/goea/{filterfactor}_{filterlevel}_lens_left_tail_tairs.txt\"\n",
    "left_file = datadir + left_file\n",
    "left_godf = godf[godf[\"Orthogroup\"].isin(corrdf_left[\"Orthogroup\"])]\n",
    "with open(left_file, \"w\") as fp:\n",
    "    fp.write(\"\\n\".join(left_godf[\"TAIRLocus\"].unique()))\n",
    "\n",
    "# List TAIR loci associated with orthogroups in the right tail and write to file\n",
    "right_file = f\"/goea/{filterfactor}_{filterlevel}_lens_right_tail_tairs.txt\"\n",
    "right_file = datadir + right_file\n",
    "right_godf = godf[godf[\"Orthogroup\"].isin(corrdf_right[\"Orthogroup\"])]\n",
    "with open(right_file, \"w\") as fp:\n",
    "    fp.write(\"\\n\".join(right_godf[\"TAIRLocus\"].unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Go enrichment analysis\n",
    "\n",
    "Once the input files are ready, we will perform the go enrichment analysis (separately for the positively and negatively correlated orthogroups). In addition to the files containing all TAIR loci, test subset of TAIR loci, and the GO associations, we also need the basic gene ontology annotation from `go-basic.obo`. This file has GO annotations filtereed in such a way that they are acyclic and can be propagated up the graph. If this file is not available in the specified location, goatools can download it for you. Once we set all the required variables and parameters, GO enrichment analysis runs pretty quickly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GO enrichment for a subset of TAIR Loci (left/right tail) against all loci\n",
    "fin_pop   = tair_file\n",
    "fin_anno  = assoc_file\n",
    "\n",
    "# Specify which tail: \"left\" or \"right\"\n",
    "tail = \"left\"\n",
    "if tail == \"left\":\n",
    "    fin_study = left_file\n",
    "else:\n",
    "    fin_study = right_file\n",
    "\n",
    "# Load the go-basic.obo file if it exists, else download it.\n",
    "fin_obo   = datadir + \"/goea/go-basic.obo\"\n",
    "if not os.path.isfile(fin_obo):\n",
    "    fin_obo = download_go_basic_obo()\n",
    "\n",
    "# Populate necessary variables to run GO Enrichment\n",
    "study_ids = read_geneset(fin_study)\n",
    "population_ids = read_geneset(fin_pop)\n",
    "godag = GODag(fin_obo)\n",
    "annoobj = IdToGosReader(fin_anno, godag=godag)\n",
    "id2gos = annoobj.get_id2gos()\n",
    "\n",
    "# GO Enrichment\n",
    "goeaobj = GOEnrichmentStudy(\n",
    "    population_ids,\n",
    "    annoobj.get_id2gos(),\n",
    "    godag,\n",
    "    methods=['bonferroni', 'fdr_bh'],\n",
    "    pvalcalc='fisher_scipy_stats')\n",
    "\n",
    "results = goeaobj.run_study_nts(study_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Writing results to a file\n",
    "\n",
    "The results of GO enrichment analysis are returned in form of an inconvenient object. To make it easier, we will convert and save them into a simple `.csv` file. We only want to see statistically significant results, i.e., when p-value is less than 0.05."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect GO Enrichment results, format and write to csv file.\n",
    "goea_out = f\"/goea/{filterfactor}_{filterlevel}_lens_{tail}_tail_goea_results\"\n",
    "goea_out = datadir + goea_out + \".csv\"\n",
    "\n",
    "# Column headers\n",
    "hdrs = [\"Namespace\", \"GO ID\", \"Enriched/Purified\", \"GO Terms\", \"pval_uncorr\", \"Benjamimi/Hochberg\", \"Bonferroni\", \"Study Ratio\", \"Population Ratio\"]\n",
    "\n",
    "# Row values pattern\n",
    "pat = \"{NS}\\t{GO}\\t{e}\\t{GOTERM}\\t{PVAL:8.2e}\\t\\\n",
    "       {BH:8.2e}\\t{BONF:8.2e}\\t{RS:>12}\\t{RP:>12}\\n\"\n",
    "\n",
    "# Write to file, one row at a time: iff adjusted p-value < 0.05\n",
    "with open(goea_out, \"w\") as fp:\n",
    "    fp.write(\"\\t\".join(hdrs) + \"\\n\")\n",
    "    for ntd in sorted(results, key=lambda nt: [nt.p_uncorrected, nt.GO]):\n",
    "        if ntd.p_fdr_bh < 0.05:\n",
    "            ogs = godf[godf[\"GO ID\"] == ntd.GO][\"Orthogroup\"].tolist()\n",
    "            fp.write(pat.format(\n",
    "                    NS=ntd.NS,\n",
    "                    GO=ntd.GO,\n",
    "                    e=ntd.enrichment,\n",
    "                    GOTERM=ntd.goterm.name,\n",
    "                    RS='{}/{}'.format(*ntd.ratio_in_study),\n",
    "                    RP='{}/{}'.format(*ntd.ratio_in_pop),\n",
    "                    PVAL=ntd.p_uncorrected,\n",
    "                    BONF=ntd.p_bonferroni,\n",
    "                    BH=ntd.p_fdr_bh))\n",
    "\n",
    "print(f\"Wrote results to {goea_out}\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0dcc173a899865200c2fbc54094f4899681c1bb4b2e5678837bb41c328db04f7"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('plant-tda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
