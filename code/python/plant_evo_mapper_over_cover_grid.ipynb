{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing mapper graphs over a grid of parameter values\n",
    "\n",
    "In this notebook, we apply the mapper algorithm to the gene expression data to compute mapper graphs across a range of cover parameters to find the range over which the structure of the graph is relatively stable. The mapper graphs generated in this notebook are used to create the stamped view illustrated in figures 2E and 2F of the manuscript. We assume that the directory structure is the same as it is in the repository. If not, you may have to check the paths and filenames to ensure the code runs without errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages\n",
    "First thing, import all the necessary packages and methods. Most of these are commonly used python packages, that can be easily installed. The only uncommon package is `kmapper` (for: *kepler mapper*), which can be pip installed. For more information and documentation, check out [this link](https://kepler-mapper.scikit-tda.org/en/latest/). We also need to import custom functions defined in the two files:\n",
    "- `helper_functions.py` and \n",
    "- `lenses.py`\n",
    "\n",
    "As the name suggests, one contains several functions required to perform utility functions such as loading and scaling input data. The other contains the function to compute the *lens* (more on that further down in the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper functions\n",
    "from helper_functions import loaddata, colorscale_from_matplotlib_cmap\n",
    "from lenses import fsga_transform\n",
    "from itertools import product\n",
    "\n",
    "# keppler mapper\n",
    "import kmapper as km\n",
    "\n",
    "# Clusterer and Scaler for mapper\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set paths, specify file names\n",
    "Next thing we want to do is set the paths to the directories containing `code`, `data`, and `results`. We also specify input files. The data to be analyzed is stored in two csv files. `clean_metadata.csv` contains the metadata, `clean_RNAseq_OutlierRemoved.csv` contains the gene expression data. \n",
    "\n",
    "The metadata file contains one sample per row, identified by its *SRA*. There are 3172 samples, and for each sample we have 7 descriptive attributes. We are particularly interested in three of them: namely, its plant *family*, *tissue* type and *stress* type. There are 16 different plant families, 8 tissue types and 10 stress types (including *healthy*) represented in the data. The RNAseq file, as the name suggests contains the gene expression for each sample, across a 6335 orthogroups. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projdir = \"../..\"\n",
    "datadir = projdir + \"/data\"\n",
    "resdir = projdir + \"/results\"\n",
    "\n",
    "factorfile = datadir + \"/clean_metadata.csv\"\n",
    "rnafile = datadir + \"/raw_RNAseq_OutlierRemoved.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "The input data (metadata and gene expression) is stored in two separate files, but samples can be matched using the *SRA*. The function `loaddata` does exactly that. It loads both files into pandas dataframes and merges them using the *SRA* as the key. We perform an inner join, to keep only those *SRAs* for which we have metadata as well as gene expression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [\"stress\", \"tissue\", \"family\"]\n",
    "df, orthos = loaddata(factorfile, rnafile, factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set factor and level for analysis\n",
    "\n",
    "Here, we set the factor, and the corresponding factor level that will be used to construct the lens function. We experimented with the following three combinations:\n",
    "- filterfactor: *stress*, filterlevel: *healthy*\n",
    "- filterfactor: *tissue*, filterlevel: *root*\n",
    "- filterfactor: *tissue*, filterlevel: *leaf*\n",
    "\n",
    "These variables are also used to construct the names of files and directories in which the results will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterfactor, filterlevel = (\"tissue\", \"leaf\")\n",
    "\n",
    "figdirname = f\"/{filterfactor}_{filterlevel}_lens_figures/mapper_over_grid\"\n",
    "figdir = resdir + figdirname\n",
    "os.makedirs(figdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying mapper\n",
    "\n",
    "The first step in applying mapper is to initialize the mapper object and set some of its attributes like the clustering algorithms and the metric used by the clustering algorithm. We will be using *DBSCAN* which is the most commonly used clustering algorithm for mapper. The metric will be the correlation distance between sample gene expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mapper object\n",
    "kmap = km.KeplerMapper(verbose=1)\n",
    "\n",
    "# Define Nerve\n",
    "nerve = km.GraphNerve(min_intersection=1)\n",
    "\n",
    "# Define clustering algorithm\n",
    "clust_metric = \"correlation\"\n",
    "clusterer = DBSCAN(metric=clust_metric)\n",
    "\n",
    "# Define colorscale to be used for node coloring\n",
    "cscale = colorscale_from_matplotlib_cmap(plt.get_cmap(\"viridis_r\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define lens / filter function\n",
    "\n",
    "Next, we need to define the *lens*. In the python file `lenses.py`, We have defined a function called *fsga_transform*. Given the filterfactor and the filterlevel of that factor (specified in the cell above), we construct a lens following the method described in [Nicolau et. al. 2011](https://www.pnas.org/content/108/17/7265).\n",
    "\n",
    "For example, for filterfactor: *stress*, and filterlevel: *healthy*, we take the gene expression profiles of all the *healthy* samples from the data and fit a linear model to obtain an idealized *healthy* gene expression profile. Then we project all the samples on to this linear model and compute the residuals. The *lens* is the norm of the residual vector, which measures how much a sample gene expression deviates from the *healthy* one.\n",
    "\n",
    "Here, we compute the lens and scale it using the standard *MinMaxScaler* from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lens\n",
    "scaler = MinMaxScaler()\n",
    "residuals, _, _ = fsga_transform(df, orthos, filterfactor, filterlevel)\n",
    "lens = kmap.project(residuals, projection=\"l2norm\", scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cover parameter ranges for the grid\n",
    "\n",
    "Next step, we specify the ranges for the cover parameter. We need to specify the range of values for number of intervals (*intervals*) and the range of values for the amount of overlap between consecutive intervals (*overlaps*). We will loop over all pairs of (interval, overlap) values in the specified range and compute mapper graphs corresponding to each pair of parameter values. The ranges set in the cell block below are the ones we settled on after some experimentation. Feel free to change them but keep in mind that overlap must be between 0 and 100. Also, note that increasing the number of intervals will make the algorithm run slower so don't increase it beyond 150 or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define ranges for cover parameters: number of intervals, percent overlap\n",
    "if filterfactor == \"tissue\":\n",
    "    if filterlevel == \"root\":\n",
    "        intervals = [100, 110, 120]\n",
    "        overlaps = [88, 90, 92]\n",
    "    else:\n",
    "        intervals = [130, 140, 150]\n",
    "        overlaps = [85, 90, 95]\n",
    "else:\n",
    "    intervals = [100, 110, 120]\n",
    "    overlaps = [70, 75, 80]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the mapper graphs\n",
    "\n",
    "With all the required components in place, we will loop over all possible pairs of (interval, overlap) values from the specified ranges. For each pair of values, we will construct the corresponding mapper graph, using the *map* method of the KepplerMapper object and create the visualization using the *visualize* method which creates an `html` file which is saved in the specified location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over combinations of cover parameters and compute mapper graphs\n",
    "for (cubes, overlap) in product(intervals, overlaps):\n",
    "    cover = km.cover.Cover(n_cubes=cubes, perc_overlap=overlap/100.)\n",
    "\n",
    "    # Create mapper graph with nodes, edges and meta-information.\n",
    "    graph = kmap.map(lens=lens,\n",
    "                        X=df[orthos],\n",
    "                        clusterer=clusterer,\n",
    "                        cover=cover,\n",
    "                        nerve=nerve,\n",
    "                        precomputed=False,\n",
    "                        remove_duplicate_nodes=True)\n",
    "\n",
    "    # Create a tooltip column\n",
    "    factor_zip = zip(df[filterfactor], lens)\n",
    "    df['tooltips'] = [f\"({str(p[0])}, {str(p[1])})\" for p in factor_zip]\n",
    "\n",
    "    # Specify file to save html output\n",
    "    fn = f\"Filter_{filterfactor}_{filterlevel}\\\n",
    "            _Cubes_{cubes}_Overlap_{overlap}.html\"\n",
    "    fpath = figdir + '/' + fn\n",
    "    figtitle = f\"Filter: {filterfactor}-{filterlevel}, \\\n",
    "                #Intervals {cubes}, overlap {overlap/100.0}\"\n",
    "\n",
    "    # Create visualization and save to specified file\n",
    "    cfname = f\"{filterfactor}_{filterlevel}_lens\"\n",
    "    mapper_data = kmap.visualize(graph,\n",
    "                                    path_html=fpath,\n",
    "                                    title=figtitle,\n",
    "                                    color_function_name=cfname,\n",
    "                                    color_values=lens,\n",
    "                                    colorscale=cscale,\n",
    "                                    custom_tooltips=df[\"tooltips\"])\n",
    "\n",
    "print(\"Mapper Over Cover Grid Completed\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('plant-tda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0dcc173a899865200c2fbc54094f4899681c1bb4b2e5678837bb41c328db04f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
