{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Applying mapper to plant gene expression data\n",
    "\n",
    "In this notebook, we apply the mapper algorithm to the gene expression data. \n",
    "We assume that the directory structure is the same as it is in the repository. \n",
    "If not, you may have to check the paths and filenames to ensure the code runs \n",
    "without errors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### import packages\n",
    "First thing, import all the necessary packages and methods. Most of these are commonly used python packages, that can be easily installed. The only uncommon package is `kmapper` (for: *kepler mapper*), which can be pip installed. For more information and documentation, check out [this link](https://kepler-mapper.scikit-tda.org/en/latest/). We also need to import custom functions defined in the two files:\n",
    "- `helper_functions.py` and \n",
    "- `lenses.py`\n",
    "\n",
    "As the name suggests, one contains several utility functions required to perform tasks such as loading and scaling input data. The other contains the function to compute the *lens* (more on that further down in the notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import webbrowser\n",
    "import pickle\n",
    "\n",
    "# Clustering, Scaling\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# keppler mapper\n",
    "import kmapper as km\n",
    "\n",
    "# Helper functions\n",
    "from helper_functions import loaddata, get_color_dict, create_pie_chart_json\n",
    "from lenses import fsga_transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set paths, specify file names\n",
    "Next thing we want to do is set the paths to the directories containing `code`, `data`, and `results`. We also specify input files. The data to be analyzed is stored in two csv files. `clean_metadata.csv` contains the metadata, `clean_RNAseq_OutlierRemoved.csv` contains the gene expression data. \n",
    "\n",
    "The metadata file contains one sample per row, identified by its *SRA*. There are 3172 samples, and for each sample we have 7 descriptive attributes. We are particularly interested in three of them: namely, its plant *family*, *tissue* type and *stress* type. There are 16 different plant families, 8 tissue types and 10 stress types (including *healthy*) represented in the data. The RNAseq file, as the name suggests contains the gene expression for each sample, across a 6335 orthogroups. \n",
    "\n",
    "The third file, named `colors.pkl`, is a pickle file (that's a python specific file format!) that contains a mapping between colors (RGB and hex codes) and the different classes of the factors (*family*, *stress* and *tissue* type). Kepler mapper outputs an `html` file visualized in a browser window, other types of plots and figures are created using `seaborn` and `matplotlib`. We have set the color mapping in a file to ensure consistency across these plotting tools used in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "projdir = \"../..\"\n",
    "datadir = projdir + \"/data\"\n",
    "resdir = projdir + \"/results\"\n",
    "codedir = projdir + \"/code\"\n",
    "\n",
    "factorfile = datadir + \"/clean_metadata.csv\"\n",
    "colorfile = datadir + \"/colors.pkl\"\n",
    "rnafile = datadir + \"/raw_RNAseq_OutlierRemoved.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading data\n",
    "\n",
    "The input data (metadata and gene expression) is stored in two separate files, but samples can be matched using the *SRA*. The function `loaddata` does exactly that. It loads both files into pandas dataframes and merges them using the *SRA* as the key. We perform an inner join, to keep only those *SRAs* for which we have metadata as well as gene expression. The `get_color_dict` is another utility function which looks for an existing `color.pkl` file and loads it. If the file is not present, the function will create it and return a dictionary containing the color mappings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "factors = [\"stress\", \"tissue\", \"family\"]\n",
    "df, orthos = loaddata(factorfile, rnafile, factors)\n",
    "color_dict = get_color_dict(df, factors, colorfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set factor and level for analysis\n",
    "\n",
    "Here, we set the factor, and the corresponding factor level that will be used to construct the lens function. We experimented with the following three combinations:\n",
    "- filterfactor: *stress*, filterlevel: *healthy*\n",
    "- filterfactor: *tissue*, filterlevel: *root*\n",
    "- filterfactor: *tissue*, filterlevel: *leaf*\n",
    "\n",
    "These variables are also used to construct the names of files and directories in which the results will be saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterfactor, filterlevel = (\"stress\", \"healthy\")\n",
    "figdir = resdir + f\"/{filterfactor}_{filterlevel}_lens_figures\"\n",
    "os.makedirs(figdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying mapper\n",
    "\n",
    "The first step in applying mapper is to initialize the mapper object and set some of its attributes like the clustering algorithms and the metric used by the clustering algorithm. We will be using *DBSCAN* which is the most commonly used clustering algorithm for mapper. The metric will be the correlation distance between sample gene expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize mapper object\n",
    "mymapper = km.KeplerMapper(verbose=1)\n",
    "\n",
    "# Define Nerve\n",
    "nerve = km.GraphNerve(min_intersection=1)\n",
    "\n",
    "# Define clustering algorithm\n",
    "clust_metric = 'correlation'\n",
    "clusterer = DBSCAN(metric=clust_metric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define lens / filter function\n",
    "\n",
    "Next, we need to define the *lens*. In the python file `lenses.py`, We have defined a function called *fsga_transform*. Given the filterfactor and the filterlevel of that factor (specified in the cell above), we construct a lens following the method described in [Nicolau et. al. 2011](https://www.pnas.org/content/108/17/7265).\n",
    "\n",
    "For example, for filterfactor: *stress*, and filterlevel: *healthy*, we take the gene expression profiles of all the *healthy* samples from the data and fit a linear model to obtain an idealized *healthy* gene expression profile. Then we project all the samples on to this linear model and compute the residuals. The *lens* is the norm of the residual vector, which measures how much a sample gene expression deviates from the *healthy* one.\n",
    "\n",
    "Here, we compute the lens and scale it using the standard *MinMaxScaler* from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define lens\n",
    "scaler = MinMaxScaler()\n",
    "residual, _, _ = fsga_transform(df, orthos, filterfactor, filterlevel)\n",
    "lens = mymapper.project(residual, projection=\"l2norm\", scaler=scaler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define cover\n",
    "\n",
    "Next step, defining a cover. We only need to specify the number of intervals (*cubes*) and the amount of overlap between consecutive intervals (*overlap*) and let kepler mapper take care of computing the cover. The values set in the cell block below are the ones we settled on after some experimentation. Feel free to change both the parameters but keep in mind that overlap must be between 0 and 100. Also, increasing the number of intervals will make the algorithm run slower so don't increase it beyond 150 or so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define cover\n",
    "if filterfactor == \"stress\":\n",
    "    cubes, overlap = (110, 75)\n",
    "elif filterfactor == \"tissue\":\n",
    "    if filterlevel == \"root\":\n",
    "        cubes, overlap = (110, 90)\n",
    "    elif filterlevel == \"leaf\":\n",
    "        cubes, overlap = (140, 90)\n",
    "    else:\n",
    "        print(\"filterlevel must be root or leaf\")\n",
    "else:\n",
    "    print(\"filterfactor must be stress or tissue\")\n",
    "\n",
    "cover = km.cover.Cover(n_cubes=cubes, perc_overlap=overlap/100.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the mapper graph\n",
    "\n",
    "With all the components required to construct the mapper graph ready, we can go ahead and call the *map* method of the KepplerMapper object which constructs the mapper graph. Keep an eye on the number of hypercubes, nodes and edges reported by the algorithm. Changing the cover parameters will change the graph size, making it denser or sparser. The computed graph is returned in form of a dictionary, we save it in a pickle file and use it later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mapper graph with nodes, edges and meta-information.\n",
    "graph = mymapper.map(lens=lens,\n",
    "                     X=df[orthos],\n",
    "                     clusterer=clusterer,\n",
    "                     cover=cover,\n",
    "                     nerve=nerve,\n",
    "                     precomputed=False,\n",
    "                     remove_duplicate_nodes=True)\n",
    "\n",
    "graph[\"lens\"] = lens.tolist()\n",
    "fname = f\"{filterfactor}_{filterlevel}_mapper_cubes_{cubes}_overlap_{overlap}\"\n",
    "fname = datadir + \"/saved_mapper_graphs/\" + fname + \".pkl\"\n",
    "with open(fname, \"wb\") as fp:\n",
    "    pickle.dump(graph, fp, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the mapper graph\n",
    "\n",
    "Lastly, we create the visualization, save it as an `html` file. Before we create the visualization, we add a couple of components to it. We will color the nodes of the mapper graph using the lens function values. The actual node color is determined averaging the colors of all samples in the corresponding cluster. We will also create tooltip that shows the factor values and lens values for samples in each cluster. If you uncomment the last line, Jupyter will also open the newly created visualization in a new browser tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe column for tooltip\n",
    "df['tooltips'] = [f'({str(p[0])}, {str(p[1])})' \n",
    "                    for p in zip(df[filterfactor], lens)]\n",
    "\n",
    "# Specify file to save html output\n",
    "fn = f\"Filter_{filterfactor}_{filterlevel}_Cubes_{cubes}_Overlap_{overlap}.html\"\n",
    "fpath = figdir + '/' + fn\n",
    "figtitle = f\"Filter: {filterfactor}-{filterlevel},\\\n",
    "             #Cubes {cubes}, Overlap: {overlap/100.0}%\"\n",
    "\n",
    "_ = mymapper.visualize(graph,\n",
    "                       path_html=fpath,\n",
    "                       title=figtitle,\n",
    "                       color_values=lens,\n",
    "                       color_function_name=\"{}_lens\".format(filterfactor),\n",
    "                       custom_tooltips=df[\"tooltips\"])\n",
    "\n",
    "# # Uncomment to open mapper graph in browser (opens in default browser)\n",
    "# webbrowser.open(fpath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapper with pie-chart nodes\n",
    "\n",
    "The nodes of the mapper graph are in fact clusters of samples. In this next part, we want to visualize these clusters in the form of pie-charts. We will replace each node by a pie-chart that shows the distribution of node memebrs with respect to a given factor. The function `create_pie_chart_json` computes the corresponding pie-charts for each node of the mapper graph and stores the information in a json file. This json file is then pulled by the javascript code to create the visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_dir = codedir + \"/kepler_mapper_pie_nodes/json_data\"\n",
    "_ = create_pie_chart_json(graph, df, factors,\n",
    "                          filterfactor, filterlevel, color_dict, json_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the mapper with pie-chart nodes\n",
    "\n",
    "After the json files are created and saved, open a terminal and go to the `code/kepler_mapper_pie_nodes` directory under the project root. Then run `python -m http.server` and once the server is running, open `http://0.0.0.8000` or `localhost:8000` in your browser. This will open up a directory listing with several html files. The filesnames follow the following pattern: \n",
    "- `<factor>_mapper_<filterfactor>_<filterlevel>_lens.html`\n",
    "\n",
    "Which means, the lens for the mapper graph was computed using *filterfactor*, and *filterlevel*, and the pie-charts show the distribution of *factor* for each node. For example, the file `family_mapper_tissue_leaf_lens.html` contains mapper graphs computed using a *tissue* lens measuring deviation from the idealized *leaf* expression and the pie charts show the distribution of plant *family* across node members."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.12 ('plant-tda')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "0dcc173a899865200c2fbc54094f4899681c1bb4b2e5678837bb41c328db04f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
